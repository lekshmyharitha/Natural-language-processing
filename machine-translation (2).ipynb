{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-06T04:47:48.336338Z","iopub.execute_input":"2021-08-06T04:47:48.336791Z","iopub.status.idle":"2021-08-06T04:47:48.365726Z","shell.execute_reply.started":"2021-08-06T04:47:48.336701Z","shell.execute_reply":"2021-08-06T04:47:48.364997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport pandas as pd\nimport numpy as np\nimport re\nfrom tqdm.notebook import tqdm","metadata":{"execution":{"iopub.status.busy":"2021-08-06T04:47:53.208143Z","iopub.execute_input":"2021-08-06T04:47:53.208457Z","iopub.status.idle":"2021-08-06T04:47:53.344064Z","shell.execute_reply.started":"2021-08-06T04:47:53.208426Z","shell.execute_reply":"2021-08-06T04:47:53.343288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/engmalay/Book1.csv')\ndf.head()\n","metadata":{"execution":{"iopub.status.busy":"2021-08-06T04:47:55.201085Z","iopub.execute_input":"2021-08-06T04:47:55.201395Z","iopub.status.idle":"2021-08-06T04:47:55.328336Z","shell.execute_reply.started":"2021-08-06T04:47:55.201365Z","shell.execute_reply":"2021-08-06T04:47:55.327556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndf = df.iloc[:10000,:]\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-06T04:48:00.247985Z","iopub.execute_input":"2021-08-06T04:48:00.248299Z","iopub.status.idle":"2021-08-06T04:48:00.261869Z","shell.execute_reply.started":"2021-08-06T04:48:00.24827Z","shell.execute_reply":"2021-08-06T04:48:00.260984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cleanerEng(x):\n  x = str(x)\n  x = x.lower()\n  x = re.sub(r'[^a-z0-9]+',' ',x)\n  if len(x) > 150:\n    x = x[:150]\n  return x\n\ndef cleanerMalayalam(x):\n  x = str(x)\n  x = re.sub(r'[-.।|,?;:<>&$₹]+',' ',x)\n  if len(x) > 150:\n    x = x[:150]\n  return x","metadata":{"execution":{"iopub.status.busy":"2021-08-06T04:49:40.312555Z","iopub.execute_input":"2021-08-06T04:49:40.312918Z","iopub.status.idle":"2021-08-06T04:49:40.318803Z","shell.execute_reply.started":"2021-08-06T04:49:40.312886Z","shell.execute_reply":"2021-08-06T04:49:40.317867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndf.iloc[:,0] = df['en'].apply(func=cleanerEng)\ndf.iloc[:,1] = df['ml'].apply(func= cleanerHindi)\ndf.iloc[:,0] = df['en'].apply(func= lambda x : (str(x).split()))\ndf.iloc[:,1] = df['ml'].apply(func= lambda x : (str(x).split()))","metadata":{"execution":{"iopub.status.busy":"2021-08-06T04:49:49.282381Z","iopub.execute_input":"2021-08-06T04:49:49.282785Z","iopub.status.idle":"2021-08-06T04:49:49.39129Z","shell.execute_reply.started":"2021-08-06T04:49:49.28275Z","shell.execute_reply":"2021-08-06T04:49:49.390402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def addTokens(x,start=False):\n  x.append('<END>')\n  if start:\n    x.insert(0,'<START>')\n  return list(x)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T04:49:53.791811Z","iopub.execute_input":"2021-08-06T04:49:53.792132Z","iopub.status.idle":"2021-08-06T04:49:53.797953Z","shell.execute_reply.started":"2021-08-06T04:49:53.792103Z","shell.execute_reply":"2021-08-06T04:49:53.796913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.iloc[:,0] = df['en'].apply(func= addTokens,start=False)\ndf.iloc[:,1] = df['ml'].apply(func= addTokens,start=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T04:50:11.684083Z","iopub.execute_input":"2021-08-06T04:50:11.68454Z","iopub.status.idle":"2021-08-06T04:50:11.736198Z","shell.execute_reply.started":"2021-08-06T04:50:11.684497Z","shell.execute_reply":"2021-08-06T04:50:11.735064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.iloc[77,0]","metadata":{"execution":{"iopub.status.busy":"2021-08-06T04:50:35.000124Z","iopub.execute_input":"2021-08-06T04:50:35.000436Z","iopub.status.idle":"2021-08-06T04:50:35.009073Z","shell.execute_reply.started":"2021-08-06T04:50:35.000406Z","shell.execute_reply":"2021-08-06T04:50:35.008315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.iloc[77,1]","metadata":{"execution":{"iopub.status.busy":"2021-08-06T04:50:13.971765Z","iopub.execute_input":"2021-08-06T04:50:13.972079Z","iopub.status.idle":"2021-08-06T04:50:13.980064Z","shell.execute_reply.started":"2021-08-06T04:50:13.972048Z","shell.execute_reply":"2021-08-06T04:50:13.979049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport random","metadata":{"execution":{"iopub.status.busy":"2021-08-06T04:50:41.002953Z","iopub.execute_input":"2021-08-06T04:50:41.003286Z","iopub.status.idle":"2021-08-06T04:50:42.197738Z","shell.execute_reply.started":"2021-08-06T04:50:41.003255Z","shell.execute_reply":"2021-08-06T04:50:42.1969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = df.values","metadata":{"execution":{"iopub.status.busy":"2021-08-06T04:50:47.21727Z","iopub.execute_input":"2021-08-06T04:50:47.217657Z","iopub.status.idle":"2021-08-06T04:50:47.221793Z","shell.execute_reply.started":"2021-08-06T04:50:47.217622Z","shell.execute_reply":"2021-08-06T04:50:47.220541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2021-08-06T04:50:57.127707Z","iopub.execute_input":"2021-08-06T04:50:57.128039Z","iopub.status.idle":"2021-08-06T04:50:57.134226Z","shell.execute_reply.started":"2021-08-06T04:50:57.12801Z","shell.execute_reply":"2021-08-06T04:50:57.133244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[:,1].shape","metadata":{"execution":{"iopub.status.busy":"2021-08-06T04:56:52.998691Z","iopub.execute_input":"2021-08-06T04:56:52.999023Z","iopub.status.idle":"2021-08-06T04:56:53.004284Z","shell.execute_reply.started":"2021-08-06T04:56:52.998994Z","shell.execute_reply":"2021-08-06T04:56:53.003517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class vocab:\n\n  def __init__(self,data,token=True):\n    self.data = data\n    if token:\n      self.word2idx = {'<START>':1, '<END>':2, '<PAD>':0}\n      self.idx2word = {1:'<START>', 2:'<END>', 0:'<PAD>'}\n      self.idx = 2\n\n    else:\n      self.word2idx = {'<PAD>':0, '<END>':1}\n      self.idx2word = {0:'<PAD>', 1:'<END>'}\n      self.idx = 1\n\n    self.x = []\n    self.create()\n    self.vocab_size = self.idx + 1\n\n  def create(self):\n    max_len = 0;\n    for sentence in  self.data:\n      max_len = max(max_len, len(sentence))\n      for word in sentence:\n        if self.word2idx.get(word) is None:\n          self.idx += 1\n          self.word2idx[word] = self.idx\n          self.idx2word[self.idx] = word\n    \n    for sentence in self.data:\n      sent = []\n      for word in sentence:\n        sent.append(self.word2idx[word])\n      \n      for i in range(len(sentence),max_len+1):\n        sent.append(0)\n      \n      self.x.append(torch.Tensor(sent))","metadata":{"execution":{"iopub.status.busy":"2021-08-06T04:57:02.925395Z","iopub.execute_input":"2021-08-06T04:57:02.925813Z","iopub.status.idle":"2021-08-06T04:57:02.934947Z","shell.execute_reply.started":"2021-08-06T04:57:02.925769Z","shell.execute_reply":"2021-08-06T04:57:02.934141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nEnglish_vocab = vocab(data[:,0],token=False)\nmalayalam_vocab = vocab(data[:,1],token=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T04:57:38.647101Z","iopub.execute_input":"2021-08-06T04:57:38.647418Z","iopub.status.idle":"2021-08-06T04:57:38.903928Z","shell.execute_reply.started":"2021-08-06T04:57:38.647381Z","shell.execute_reply":"2021-08-06T04:57:38.902923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(malayalam_vocab)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T04:57:41.354861Z","iopub.execute_input":"2021-08-06T04:57:41.355207Z","iopub.status.idle":"2021-08-06T04:57:41.360802Z","shell.execute_reply.started":"2021-08-06T04:57:41.355176Z","shell.execute_reply":"2021-08-06T04:57:41.359843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for idx in malayalam_vocab.x[2]:\n  print(malayalam_vocab.idx2word[int(idx)],end=' ')","metadata":{"execution":{"iopub.status.busy":"2021-08-06T04:57:45.925369Z","iopub.execute_input":"2021-08-06T04:57:45.925841Z","iopub.status.idle":"2021-08-06T04:57:45.946424Z","shell.execute_reply.started":"2021-08-06T04:57:45.925802Z","shell.execute_reply":"2021-08-06T04:57:45.945605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class parallelData(Dataset):\n\n  def __init__(self):\n    self.x = English_vocab.x\n    self.y = malayalam_vocab.x\n\n  def __getitem__(self,i):\n    return self.x[i], self.y[i]\n  \n  def __len__(self):\n    return len(self.x)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T04:58:31.232247Z","iopub.execute_input":"2021-08-06T04:58:31.232613Z","iopub.status.idle":"2021-08-06T04:58:31.239176Z","shell.execute_reply.started":"2021-08-06T04:58:31.23258Z","shell.execute_reply":"2021-08-06T04:58:31.238056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = parallelData()","metadata":{"execution":{"iopub.status.busy":"2021-08-06T04:58:34.499149Z","iopub.execute_input":"2021-08-06T04:58:34.499464Z","iopub.status.idle":"2021-08-06T04:58:34.502976Z","shell.execute_reply.started":"2021-08-06T04:58:34.499435Z","shell.execute_reply":"2021-08-06T04:58:34.50197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = dataset[0][0].shape[0]\nb = dataset[0][1].shape[0]\nfor i in range(len(dataset)):\n  if a != dataset[i][0].shape[0] or b != dataset[i][1].shape[0]:\n    print(a,dataset[i][0].shape[0],b,dataset[i][1].shape[0])","metadata":{"execution":{"iopub.status.busy":"2021-08-06T04:58:37.73807Z","iopub.execute_input":"2021-08-06T04:58:37.738518Z","iopub.status.idle":"2021-08-06T04:58:37.774932Z","shell.execute_reply.started":"2021-08-06T04:58:37.738471Z","shell.execute_reply":"2021-08-06T04:58:37.774029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"malayalam_vocab.x[90]","metadata":{"execution":{"iopub.status.busy":"2021-08-06T04:58:51.130599Z","iopub.execute_input":"2021-08-06T04:58:51.130913Z","iopub.status.idle":"2021-08-06T04:58:51.173318Z","shell.execute_reply.started":"2021-08-06T04:58:51.130886Z","shell.execute_reply":"2021-08-06T04:58:51.172371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmalayalam_vocab.x[90].shape","metadata":{"execution":{"iopub.status.busy":"2021-08-06T04:58:40.945472Z","iopub.execute_input":"2021-08-06T04:58:40.945835Z","iopub.status.idle":"2021-08-06T04:58:40.951936Z","shell.execute_reply.started":"2021-08-06T04:58:40.945805Z","shell.execute_reply":"2021-08-06T04:58:40.950699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntorch.cuda.device_count()\n","metadata":{"execution":{"iopub.status.busy":"2021-08-06T04:59:00.941849Z","iopub.execute_input":"2021-08-06T04:59:00.942171Z","iopub.status.idle":"2021-08-06T04:59:01.00178Z","shell.execute_reply.started":"2021-08-06T04:59:00.942141Z","shell.execute_reply":"2021-08-06T04:59:01.000884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Model preparation\n\nclass encoder(nn.Module):\n\n  def __init__(self, input_size, embedding_size, hidden_size, layers, bidirectional):\n    '''\n    input_size = size of vocab\n    embedding_size = embedding dim\n    hidden_size = hidden state size\n    layer = num of layers of lstms\n    '''\n    super().__init__()\n    self.embed = nn.Embedding(num_embeddings=input_size, embedding_dim=embedding_size) # output size = (*,embedding_size)\n    self.lstm = nn.LSTM(input_size=embedding_size, hidden_size= hidden_size, num_layers=layers, batch_first = True, bidirectional = bidirectional)\n    self.bidirectional = bidirectional\n    #in order to convert bidirectional hidden state to unidirectional if LSTM is bidirectional \n    self.fc_hidden = nn.Linear(hidden_size*2, hidden_size)\n    self.fc_cell = nn.Linear(hidden_size*2, hidden_size)\n\n  def forward(self,x):\n    '''\n    x shape = [batch_size, sentence]\n    one complete sentence represents a \"sequence\"\n    '''\n    x = self.embed(x) # shape [batch_size,  sentence, embed_size]\n    output, (hidden_state, cell_state) = self.lstm(x) #shape [batch_size, seq_len, num_directions(2)*hidden_size]\n\n    if self.bidirectional:  #since we have 2 directions so add(concat) hidden of both directions into one\n      hidden = torch.cat((hidden_state[0:1], hidden_state[1:2]), dim=2)\n      cell = torch.cat((cell_state[0:1], cell_state[1:2]), dim = 2) #output [1(layer), batch, hidden_size*2]\n      hidden_state = self.fc_hidden(hidden)\n      cell_state = self.fc_cell(cell)\n\n    # print(output.shape, x.shape)\n    #output shape = [batch_size, seq_len, 2*hidden_size] \n    #hidden shape =[1(layers), batch_size, hidden_size]\n    return output, hidden_state, cell_state","metadata":{"execution":{"iopub.status.busy":"2021-08-06T04:59:03.981588Z","iopub.execute_input":"2021-08-06T04:59:03.981929Z","iopub.status.idle":"2021-08-06T04:59:03.991333Z","shell.execute_reply.started":"2021-08-06T04:59:03.981894Z","shell.execute_reply":"2021-08-06T04:59:03.990557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class decoder(nn.Module):\n\n  def __init__(self,input_size, embedding_size, hidden_size, layers):\n    '''\n    same configuration as encoder\n    here input_size = size of hindi vocab\n    '''\n    super().__init__()\n    self.embed = nn.Embedding(num_embeddings=input_size, embedding_dim=embedding_size) # output size = (*,embedding_size)\n    self.lstm = nn.LSTM(input_size=embedding_size, hidden_size= hidden_size, num_layers=layers, batch_first = True)\n    self.fc = nn.Linear(in_features=hidden_size, out_features=input_size) #since output would be prob distribution among hindi vocab therefore out_feature=input_size\n\n  def forward(self,x,hidden_state, cell_state):\n    '''\n    to have control over output we have to take sentence as word by word\n    therefore seq_len would be 1 as input is  one word not the whole sentence\n    x = [batch_size] ->required-> [batch_size, 1] (1 is seq_len)\n    '''\n    # print(x.shape)\n    x = x.reshape(-1,1) # shape [batch, 1]\n    # print(x.shape)\n    x = self.embed(x) # shape [batch, 1, embed_dim]\n\n    output, (hidden_state, cell_state) = self.lstm(x, (hidden_state, cell_state)) # shape output=>[batch, 1, hidden_size], hidden=>[layers, batch, hidden_size]\n    output = self.fc(output) # shape [batch, 1, hindi_vocab_size]\n    \n    #just for removing extra dim\n    output = output.squeeze(dim=1) #shape [batch, hindi_vocab_size]\n\n    return output, hidden_state, cell_state","metadata":{"execution":{"iopub.status.busy":"2021-08-06T04:59:08.027061Z","iopub.execute_input":"2021-08-06T04:59:08.027455Z","iopub.status.idle":"2021-08-06T04:59:08.03827Z","shell.execute_reply.started":"2021-08-06T04:59:08.02741Z","shell.execute_reply":"2021-08-06T04:59:08.036938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AttnDecoder(nn.Module):\n  def __init__(self, input_size, embedding_size, hidden_size, layers):\n    super().__init__()\n\n    self.embed = nn.Embedding(num_embeddings=input_size, embedding_dim=embedding_size) # output size = (*,embedding_size)\n    self.lstm = nn.LSTM(input_size=hidden_size*2 + embedding_size, hidden_size= hidden_size, num_layers=layers, batch_first = True)\n    self.fc = nn.Linear(in_features=hidden_size, out_features=input_size) #since output would be prob distribution among hindi vocab therefore out_feature=input_size\n\n    #encoder_states from encoder => [batch, seq_len(35), 2*hidden_size]\n    #prev decoder hidden_state => [batch, layers(1)*directions(2), hidden_size] =>need to be in => [batch, seq(35), hidden_size]\n    #therefore input of energy will be along hidden_size ie input = hidden_size*2\n    self.energy =  nn.Linear(hidden_size*3, 1) #out [batch, seq_len, 1] (2 hidden state from bidirectional encoder and 1 from prev decoder hidden state => 1+2= 3 hidden states as input)\n    self.softmax = nn.Softmax(dim=1)# doing softmax for each word ie (dim=1)\n\n  \n  def forward(self, x, hidden_state, cell_state, encoder_states):\n    # print(encoder_states.shape)\n    seq_len = encoder_states.shape[1]\n    batch_size = encoder_states.shape[0]\n    hidden_size = encoder_states.shape[2]\n\n    h_new = hidden_state.repeat(seq_len, 1, 1) #shape [seq_len*1, batch, hidden_size*2(bidirectional)] it will repeat dim=0 seq length times\n    #by doing .repeat operation we can concat hidden state with all timestamps of encoder_states\n    # print(h_new.shape, encoder_states.shape, hidden_state.shape)\n    h_new = h_new.permute(1,0,2) #[batch, seq_len, hidden_size*2]\n    energy = self.energy(torch.cat((h_new, encoder_states), dim=2))#input [batch, seq_len(35), hidden_size*3]  out = [batch, seq_len(35), 1]\n    att_weights = self.softmax(energy)\n    att_weights = att_weights.permute(0,2,1) # [batch, 1, seq_len]\n\n    context = torch.bmm(att_weights, encoder_states) #[batch, 1, hidden_size*2]\n    \n\n    x = x.reshape(-1,1) # shape [batch, 1]\n    x = self.embed(x) # shape [batch, 1, embed_dim]\n\n    input_new = torch.cat((context, x), dim=2) #[batch, 1, hidden_size*2 +embed_dim]\n\n    output, (hidden_state, cell_state) = self.lstm(input_new, (hidden_state, cell_state)) # shape output=>[batch, 1, hidden_size], hidden=>[layers, batch, hidden_size]\n    output = self.fc(output) # shape [batch, 1, hindi_vocab_size]\n\n    output = output.squeeze(dim=1) #shape [batch, hindi_vocab_size]\n    del h_new\n    del context\n    del input_new\n    return output, hidden_state, cell_state\n","metadata":{"execution":{"iopub.status.busy":"2021-08-06T04:59:11.396578Z","iopub.execute_input":"2021-08-06T04:59:11.396911Z","iopub.status.idle":"2021-08-06T04:59:11.407114Z","shell.execute_reply.started":"2021-08-06T04:59:11.396883Z","shell.execute_reply":"2021-08-06T04:59:11.406293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class seq2seq(nn.Module):\n  def __init__(self, encoder, decoder):\n    super().__init__()\n    self.encoder = encoder\n    self.decoder = decoder\n\n\n  def forward(self, input, target, teaching_force=0.5):\n    '''\n    input = batch of english sentences[batch, sentece(padded)]\n    target = batch of hindi sentences [batch, sentence(padded)] \n    '''\n    batch_size = input.shape[0]\n    seq_len = target.shape[1]\n    Malayalam_vocab_size = malayalam_vocab.vocab_size\n\n    output = torch.zeros((seq_len, batch_size, Malayalam_vocab_size)).to(device)\n\n    _, hidden, cell = self.encoder(input)\n    target = target.permute(1,0) # shape [seq, batch]\n    x = target[0] # <START> token\n\n    for i in range(1, seq_len):\n      out, hidden, cell = self.decoder(x, hidden, cell) #out shape = [batch, vocab_size]\n      output[i] = out\n      decoder_guess = out.argmax(1)# taking the word with max value(confidence)  shape = [batch of words]\n\n      if random.random() < teaching_force:\n        x = target[i]\n      else:\n        x =  decoder_guess\n    \n    return output  #shape[seq_len, batch_size, vocab_size]\n","metadata":{"execution":{"iopub.status.busy":"2021-08-06T05:02:33.655032Z","iopub.execute_input":"2021-08-06T05:02:33.655352Z","iopub.status.idle":"2021-08-06T05:02:33.66343Z","shell.execute_reply.started":"2021-08-06T05:02:33.655321Z","shell.execute_reply":"2021-08-06T05:02:33.662425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Attnseq2seq(nn.Module):\n  def __init__(self, encoder, att_decoder):\n    super().__init__()\n    self.encoder = encoder\n    self.decoder = att_decoder\n\n\n  def forward(self, input, target, teaching_force=0.5):\n    '''\n    input = batch of english sentences[batch, sentece(padded)]\n    target = batch of hindi sentences [batch, sentence(padded)] \n    '''\n    batch_size = input.shape[0]\n    seq_len = target.shape[1]\n    Malayalam_vocab_size = malayalam_vocab.vocab_size\n\n    output = torch.zeros((seq_len, batch_size, Malayalam_vocab_size)).to(device)\n\n    encoder_states, hidden, cell = self.encoder(input)\n    target = target.permute(1,0) # shape [seq, batch]\n    x = target[0] # <START> token\n\n    for i in range(1, seq_len):\n      out, hidden, cell = self.decoder(x, hidden, cell, encoder_states) #out shape = [batch, vocab_size]\n      output[i] = out\n      decoder_guess = out.argmax(1)# taking the word with max value(confidence)  shape = [batch of words]\n\n      if random.random() < teaching_force:\n        x = target[i]\n      else:\n        x =  decoder_guess\n    \n    return output  #shape[seq_len, batch_size, vocab_size]","metadata":{"execution":{"iopub.status.busy":"2021-08-06T05:02:35.925254Z","iopub.execute_input":"2021-08-06T05:02:35.925588Z","iopub.status.idle":"2021-08-06T05:02:35.933145Z","shell.execute_reply.started":"2021-08-06T05:02:35.925557Z","shell.execute_reply":"2021-08-06T05:02:35.932177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##training\nepochs = 120\nlearning_rate = 0.0006\nbatch_size = 100\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nembedding_size = 256\nhidden_size = 256\nlayers = 1\nbidirection = True\n","metadata":{"execution":{"iopub.status.busy":"2021-08-06T05:02:39.373967Z","iopub.execute_input":"2021-08-06T05:02:39.374281Z","iopub.status.idle":"2021-08-06T05:02:39.379048Z","shell.execute_reply.started":"2021-08-06T05:02:39.37425Z","shell.execute_reply":"2021-08-06T05:02:39.377892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T04:59:29.406038Z","iopub.execute_input":"2021-08-06T04:59:29.406357Z","iopub.status.idle":"2021-08-06T04:59:29.410999Z","shell.execute_reply.started":"2021-08-06T04:59:29.406326Z","shell.execute_reply":"2021-08-06T04:59:29.4101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"it = iter(loader)\nx,y = next(it)\nprint(x.shape,y.shape)\nlen(dataset)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T05:02:42.608397Z","iopub.execute_input":"2021-08-06T05:02:42.608791Z","iopub.status.idle":"2021-08-06T05:02:42.622367Z","shell.execute_reply.started":"2021-08-06T05:02:42.60876Z","shell.execute_reply":"2021-08-06T05:02:42.621513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ENC = encoder(English_vocab.vocab_size, embedding_size, hidden_size, layers, bidirection).to(device)\n# DE = decoder(Hindi_vocab.vocab_size, embedding_size, hidden_size, layers).to(device)\nDE = AttnDecoder(malayalam_vocab.vocab_size, embedding_size, hidden_size, layers).to(device)\n# model = seq2seq(ENC,DE).to(device)\nmodel = Attnseq2seq(ENC,DE).to(device)\noptimizer = optim.Adam(model.parameters(),lr=learning_rate)\ncriterion = nn.CrossEntropyLoss(ignore_index=0)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T05:02:44.056674Z","iopub.execute_input":"2021-08-06T05:02:44.057056Z","iopub.status.idle":"2021-08-06T05:02:44.121693Z","shell.execute_reply.started":"2021-08-06T05:02:44.057025Z","shell.execute_reply":"2021-08-06T05:02:44.120871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loss = []\nfor epoch in tqdm(range(epochs)):\n  for id,(x,y) in (enumerate(tqdm(loader))):\n    x = x.long().to(device)\n    y = y.long().to(device)#[batch,seq]\n\n    output = model(x,y,1)# [seq, batch, vocab]\n    output = output[1:].reshape(-1,output.shape[2])\n    y = y.permute(1,0)#[seq, batch]\n    y = y[1:].reshape(-1)\n\n    optimizer.zero_grad()\n    loss = criterion(output,y)\n\n    loss.backward()\n    optimizer.step()\n\n    # if id%20 == 0:\n  print(f'[{epoch+1}/{epochs}] loss=>{loss.item()}')\n  train_loss.append(loss.item())","metadata":{"execution":{"iopub.status.busy":"2021-08-06T05:02:46.128888Z","iopub.execute_input":"2021-08-06T05:02:46.129202Z","iopub.status.idle":"2021-08-06T05:11:38.210209Z","shell.execute_reply.started":"2021-08-06T05:02:46.129173Z","shell.execute_reply":"2021-08-06T05:11:38.209379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(train_loss)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-06T05:12:53.14945Z","iopub.execute_input":"2021-08-06T05:12:53.149795Z","iopub.status.idle":"2021-08-06T05:12:53.300094Z","shell.execute_reply.started":"2021-08-06T05:12:53.149766Z","shell.execute_reply":"2021-08-06T05:12:53.299136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(),'model.pt')","metadata":{"execution":{"iopub.status.busy":"2021-08-06T05:12:55.481867Z","iopub.execute_input":"2021-08-06T05:12:55.482236Z","iopub.status.idle":"2021-08-06T05:12:55.537855Z","shell.execute_reply.started":"2021-08-06T05:12:55.482204Z","shell.execute_reply":"2021-08-06T05:12:55.536924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prediction(x):\n    for idx in x:\n      if idx == 0:\n        break\n      print(English_vocab.idx2word[int(idx)],end=' ')\n    \n    print()\n\n    x = x.long().reshape(1,-1).to(device)\n    ans = translate(x)\n    res = []\n    for id in ans:\n      res.append(malayalam_vocab.idx2word[id])\n    \n    return res","metadata":{"execution":{"iopub.status.busy":"2021-08-06T05:13:27.07607Z","iopub.execute_input":"2021-08-06T05:13:27.076388Z","iopub.status.idle":"2021-08-06T05:13:27.082994Z","shell.execute_reply.started":"2021-08-06T05:13:27.076358Z","shell.execute_reply":"2021-08-06T05:13:27.081521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def translate(input):\n      #input = batch of english sentences[batch, sentece(padded)]\n      with torch.no_grad():\n        guess = []\n        encoder_states, hidden, cell = model.encoder(input)\n        # x = torch.ones((1)).float().to(device) # <START> token\n        x = torch.ones((1)).long().to(device)\n        while True:\n          out, hidden, cell = model.decoder(x, hidden, cell, encoder_states) #out shape = [batch, vocab_size]\n          x = out.argmax(1)# taking the word with max value(confidence)  shape = [batch of words]\n          guess.append(int(x[0].detach().cpu()))\n\n          if x == 2:\n            break\n\n      return guess","metadata":{"execution":{"iopub.status.busy":"2021-08-06T05:15:05.564444Z","iopub.execute_input":"2021-08-06T05:15:05.56479Z","iopub.status.idle":"2021-08-06T05:15:05.570746Z","shell.execute_reply.started":"2021-08-06T05:15:05.56476Z","shell.execute_reply":"2021-08-06T05:15:05.569727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction(dataset[50][0])","metadata":{"execution":{"iopub.status.busy":"2021-08-06T05:15:09.27952Z","iopub.execute_input":"2021-08-06T05:15:09.279841Z","iopub.status.idle":"2021-08-06T05:15:09.296162Z","shell.execute_reply.started":"2021-08-06T05:15:09.27981Z","shell.execute_reply":"2021-08-06T05:15:09.295407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction(dataset[100][0])","metadata":{"execution":{"iopub.status.busy":"2021-08-06T05:13:48.505617Z","iopub.execute_input":"2021-08-06T05:13:48.505934Z","iopub.status.idle":"2021-08-06T05:13:48.520535Z","shell.execute_reply.started":"2021-08-06T05:13:48.505905Z","shell.execute_reply":"2021-08-06T05:13:48.519581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction(dataset[72][0])","metadata":{"execution":{"iopub.status.busy":"2021-08-06T05:15:39.445945Z","iopub.execute_input":"2021-08-06T05:15:39.446256Z","iopub.status.idle":"2021-08-06T05:15:39.462806Z","shell.execute_reply.started":"2021-08-06T05:15:39.446226Z","shell.execute_reply":"2021-08-06T05:15:39.461988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction(dataset[random.randint(0,10000)][0])","metadata":{"execution":{"iopub.status.busy":"2021-08-06T05:15:52.440702Z","iopub.execute_input":"2021-08-06T05:15:52.441021Z","iopub.status.idle":"2021-08-06T05:15:52.45522Z","shell.execute_reply.started":"2021-08-06T05:15:52.440989Z","shell.execute_reply":"2021-08-06T05:15:52.454221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(15):\n  prediction(dataset[random.randint(0,10000)][0])","metadata":{"execution":{"iopub.status.busy":"2021-08-06T05:15:54.560405Z","iopub.execute_input":"2021-08-06T05:15:54.560763Z","iopub.status.idle":"2021-08-06T05:15:54.653678Z","shell.execute_reply.started":"2021-08-06T05:15:54.560731Z","shell.execute_reply":"2021-08-06T05:15:54.652864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset[3][0]\n","metadata":{"execution":{"iopub.status.busy":"2021-08-06T05:16:10.51283Z","iopub.execute_input":"2021-08-06T05:16:10.513156Z","iopub.status.idle":"2021-08-06T05:16:10.521043Z","shell.execute_reply.started":"2021-08-06T05:16:10.513124Z","shell.execute_reply":"2021-08-06T05:16:10.520142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get(sent):\n  # sentence = sentence.lower()\n  # sent = sentence.split()\n  # sent.append('<END>')\n  # print(sent)\n\n  toks = []\n  for word in sent:\n    if English_vocab.word2idx.get(word) is None:\n      toks.append(English_vocab.word2idx['the'])\n    else:\n      toks.append(English_vocab.word2idx[word])\n  # print(toks)\n  sent = torch.tensor(toks).float()\n  res = prediction(sent)\n  # print(res)\n  return res","metadata":{"execution":{"iopub.status.busy":"2021-08-06T05:16:13.984117Z","iopub.execute_input":"2021-08-06T05:16:13.984423Z","iopub.status.idle":"2021-08-06T05:16:13.989322Z","shell.execute_reply.started":"2021-08-06T05:16:13.984392Z","shell.execute_reply":"2021-08-06T05:16:13.988544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tdf = pd.read_csv('../input/malayalamtestnew/malayalamtestnew.csv')\n#tdf = tdf.iloc[5000:7000,:]\n","metadata":{"execution":{"iopub.status.busy":"2021-08-06T05:35:04.062622Z","iopub.execute_input":"2021-08-06T05:35:04.062961Z","iopub.status.idle":"2021-08-06T05:35:04.074573Z","shell.execute_reply.started":"2021-08-06T05:35:04.062929Z","shell.execute_reply":"2021-08-06T05:35:04.073745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tdf.iloc[:,0] = tdf['en'].apply(func=cleanerEng)\ntdf.iloc[:,1] = tdf['ml'].apply(func= cleanerHindi)\ntdf.iloc[:,0] = tdf['en'].apply(func= lambda x : (str(x).split()))\ntdf.iloc[:,1] = tdf['ml'].apply(func= lambda x : (str(x).split()))","metadata":{"execution":{"iopub.status.busy":"2021-08-06T05:35:09.120076Z","iopub.execute_input":"2021-08-06T05:35:09.120402Z","iopub.status.idle":"2021-08-06T05:35:09.146531Z","shell.execute_reply.started":"2021-08-06T05:35:09.120372Z","shell.execute_reply":"2021-08-06T05:35:09.145534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tdf.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-06T05:35:14.766013Z","iopub.execute_input":"2021-08-06T05:35:14.766326Z","iopub.status.idle":"2021-08-06T05:35:14.780381Z","shell.execute_reply.started":"2021-08-06T05:35:14.766296Z","shell.execute_reply":"2021-08-06T05:35:14.779507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tdf.iloc[:,0] = tdf['en'].apply(func= addTokens,start=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T05:35:21.950442Z","iopub.execute_input":"2021-08-06T05:35:21.950814Z","iopub.status.idle":"2021-08-06T05:35:21.957406Z","shell.execute_reply.started":"2021-08-06T05:35:21.950783Z","shell.execute_reply":"2021-08-06T05:35:21.9565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tdf.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T05:35:23.68605Z","iopub.execute_input":"2021-08-06T05:35:23.686361Z","iopub.status.idle":"2021-08-06T05:35:23.70262Z","shell.execute_reply.started":"2021-08-06T05:35:23.686331Z","shell.execute_reply":"2021-08-06T05:35:23.701612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntdata = tdf.values\ntest_dataset = vocab(tdata[:,0],token=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T05:35:31.372526Z","iopub.execute_input":"2021-08-06T05:35:31.372863Z","iopub.status.idle":"2021-08-06T05:35:31.39756Z","shell.execute_reply.started":"2021-08-06T05:35:31.372831Z","shell.execute_reply":"2021-08-06T05:35:31.396722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntdata = tdf.values\ntest_dataset = vocab(tdata[:,0],token=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T05:35:34.004764Z","iopub.execute_input":"2021-08-06T05:35:34.0051Z","iopub.status.idle":"2021-08-06T05:35:34.026874Z","shell.execute_reply.started":"2021-08-06T05:35:34.005068Z","shell.execute_reply":"2021-08-06T05:35:34.026098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res = get(tdata[121,0])[:-1]\nprint(res)\nprint(tdata[121,0][:-1])","metadata":{"execution":{"iopub.status.busy":"2021-08-06T05:45:52.950552Z","iopub.execute_input":"2021-08-06T05:45:52.950908Z","iopub.status.idle":"2021-08-06T05:45:52.964401Z","shell.execute_reply.started":"2021-08-06T05:45:52.950861Z","shell.execute_reply":"2021-08-06T05:45:52.963518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_refrences = []\nlist_hypothesis = []\nfor i in tqdm(range(int(tdata.shape[0]/2))):\n  list_refrences.append(tdata[i,0][:-1])\n  list_hypothesis.append((get(tdata[i,0])[:-1]))","metadata":{"execution":{"iopub.status.busy":"2021-08-06T05:36:35.846349Z","iopub.execute_input":"2021-08-06T05:36:35.846739Z","iopub.status.idle":"2021-08-06T05:36:40.582128Z","shell.execute_reply.started":"2021-08-06T05:36:35.846703Z","shell.execute_reply":"2021-08-06T05:36:40.581292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\nprint(f\"bleu-1 : {nltk.translate.bleu_score.corpus_bleu(list_refrences, list_hypothesis, weights=(1.0,0.0,0.0,0.0))}\")\nprint(f\"bleu-2 : {nltk.translate.bleu_score.corpus_bleu(list_refrences, list_hypothesis, weights=(0.5,0.5,0.0))}\")\nprint(f\"bleu-3 : {nltk.translate.bleu_score.corpus_bleu(list_refrences, list_hypothesis, weights=(0.33,0.33,0.33,0.0))}\")\nprint(f\"bleu-4 : {nltk.translate.bleu_score.corpus_bleu(list_refrences, list_hypothesis, weights=(0.25,0.25,0.25,0.25))}\")","metadata":{"execution":{"iopub.status.busy":"2021-08-06T05:44:28.043017Z","iopub.execute_input":"2021-08-06T05:44:28.043329Z","iopub.status.idle":"2021-08-06T05:44:28.608776Z","shell.execute_reply.started":"2021-08-06T05:44:28.0433Z","shell.execute_reply":"2021-08-06T05:44:28.607743Z"},"trusted":true},"execution_count":null,"outputs":[]}]}