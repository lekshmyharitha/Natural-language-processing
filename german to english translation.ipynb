{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-15T09:12:48.483376Z","iopub.execute_input":"2021-08-15T09:12:48.483696Z","iopub.status.idle":"2021-08-15T09:12:48.489044Z","shell.execute_reply.started":"2021-08-15T09:12:48.483661Z","shell.execute_reply":"2021-08-15T09:12:48.487981Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"pip install torch===1.5.0 torchvision===0.6.0 -f https://download.pytorch.org/whl/torch_stable.html","metadata":{"execution":{"iopub.status.busy":"2021-08-15T09:20:39.745685Z","iopub.execute_input":"2021-08-15T09:20:39.746078Z","iopub.status.idle":"2021-08-15T09:22:09.543237Z","shell.execute_reply.started":"2021-08-15T09:20:39.745990Z","shell.execute_reply":"2021-08-15T09:22:09.542323Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Looking in links: https://download.pytorch.org/whl/torch_stable.html\nCollecting torch===1.5.0\n  Downloading torch-1.5.0-cp37-cp37m-manylinux1_x86_64.whl (752.0 MB)\n\u001b[K     |████████████████████████████████| 752.0 MB 6.7 kB/s  eta 0:00:01     |████████████▌                   | 295.0 MB 45.3 MB/s eta 0:00:11     |████████████▊                   | 298.7 MB 45.3 MB/s eta 0:00:11     |███████████████████▌            | 458.1 MB 22.9 MB/s eta 0:00:13     |█████████████████████████████▎  | 687.6 MB 26.3 MB/s eta 0:00:03     |█████████████████████████████▎  | 688.5 MB 26.3 MB/s eta 0:00:03     |█████████████████████████████▉  | 700.0 MB 26.3 MB/s eta 0:00:02     |██████████████████████████████▌ | 717.8 MB 56.5 MB/s eta 0:00:01\n\u001b[?25hCollecting torchvision===0.6.0\n  Downloading torchvision-0.6.0-cp37-cp37m-manylinux1_x86_64.whl (6.6 MB)\n\u001b[K     |████████████████████████████████| 6.6 MB 10 kB/s s eta 0:00:01     |████                            | 829 kB 51.6 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch===1.5.0) (0.18.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch===1.5.0) (1.19.5)\nRequirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision===0.6.0) (8.2.0)\nInstalling collected packages: torch, torchvision\n  Attempting uninstall: torch\n    Found existing installation: torch 1.7.0\n    Uninstalling torch-1.7.0:\n      Successfully uninstalled torch-1.7.0\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.8.1\n    Uninstalling torchvision-0.8.1:\n      Successfully uninstalled torchvision-0.8.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkornia 0.5.5 requires numpy<=1.19, but you have numpy 1.19.5 which is incompatible.\nkornia 0.5.5 requires torch>=1.6.0, but you have torch 1.5.0 which is incompatible.\nfastai 2.2.7 requires torch<1.8,>=1.7.0, but you have torch 1.5.0 which is incompatible.\nfastai 2.2.7 requires torchvision<0.9,>=0.8, but you have torchvision 0.6.0 which is incompatible.\nallennlp 2.5.0 requires torch<1.9.0,>=1.6.0, but you have torch 1.5.0 which is incompatible.\nallennlp 2.5.0 requires torchvision<0.10.0,>=0.8.1, but you have torchvision 0.6.0 which is incompatible.\u001b[0m\nSuccessfully installed torch-1.5.0 torchvision-0.6.0\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nfrom torchtext.datasets import Multi30k\nfrom torchtext.data import Field ,BucketIterator\nimport spacy\nimport random\nimport math\nimport os","metadata":{"execution":{"iopub.status.busy":"2021-08-15T09:22:17.628499Z","iopub.execute_input":"2021-08-15T09:22:17.628841Z","iopub.status.idle":"2021-08-15T09:22:19.958153Z","shell.execute_reply.started":"2021-08-15T09:22:17.628812Z","shell.execute_reply":"2021-08-15T09:22:19.957313Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#make sure code is repeatable\n\nSEED=2222\nrandom.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.backends.cudnn.deterministic=True","metadata":{"execution":{"iopub.status.busy":"2021-08-15T09:22:23.627151Z","iopub.execute_input":"2021-08-15T09:22:23.627516Z","iopub.status.idle":"2021-08-15T09:22:23.632777Z","shell.execute_reply.started":"2021-08-15T09:22:23.627485Z","shell.execute_reply":"2021-08-15T09:22:23.631924Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"pip install spacy download en","metadata":{"execution":{"iopub.status.busy":"2021-08-15T09:22:27.819474Z","iopub.execute_input":"2021-08-15T09:22:27.819799Z","iopub.status.idle":"2021-08-15T09:22:30.030770Z","shell.execute_reply.started":"2021-08-15T09:22:27.819768Z","shell.execute_reply":"2021-08-15T09:22:30.029626Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Requirement already satisfied: spacy in /opt/conda/lib/python3.7/site-packages (2.3.7)\nCollecting download\n  Downloading download-0.3.5-py3-none-any.whl (8.8 kB)\n\u001b[31mERROR: Could not find a version that satisfies the requirement en (from versions: none)\u001b[0m\n\u001b[31mERROR: No matching distribution found for en\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"'''\nUsed in jupyternotebook -Not pipeline\nspacy_de=spacy.load('de')\nspacy_en=spacy.load('en')\n'''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#downloading spacy pipeline for english\nimport spacy.cli \nspacy.cli.download(\"en_core_web_md\")","metadata":{"execution":{"iopub.status.busy":"2021-08-15T09:22:34.139641Z","iopub.execute_input":"2021-08-15T09:22:34.139972Z","iopub.status.idle":"2021-08-15T09:22:50.367474Z","shell.execute_reply.started":"2021-08-15T09:22:34.139938Z","shell.execute_reply":"2021-08-15T09:22:50.366468Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the model via spacy.load('en_core_web_md')\n","output_type":"stream"}]},{"cell_type":"code","source":"#downloading spacy pipeline for german\nimport spacy.cli \nspacy.cli.download(\"de_core_news_sm\")","metadata":{"execution":{"iopub.status.busy":"2021-08-15T09:22:52.582640Z","iopub.execute_input":"2021-08-15T09:22:52.583006Z","iopub.status.idle":"2021-08-15T09:23:05.005200Z","shell.execute_reply.started":"2021-08-15T09:22:52.582972Z","shell.execute_reply":"2021-08-15T09:23:05.004128Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the model via spacy.load('de_core_news_sm')\n","output_type":"stream"}]},{"cell_type":"code","source":"#loading pipeline for \nspacy_de=spacy.load('de_core_news_sm')\nspacy_en = spacy.load(\"en_core_web_sm\")","metadata":{"execution":{"iopub.status.busy":"2021-08-15T09:24:22.506432Z","iopub.execute_input":"2021-08-15T09:24:22.506795Z","iopub.status.idle":"2021-08-15T09:24:25.155806Z","shell.execute_reply.started":"2021-08-15T09:24:22.506758Z","shell.execute_reply":"2021-08-15T09:24:25.154929Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#function for tokenizing the text\n'''\nWe will pass data into each model for processing it. Field module from torchtext helps in tokenzing . And convets tokens into lower case.Seq model pad start and stop tokens in the front and back of sequnce.So bascially torchtext works on this an convet a sequnce into takens and pad start and stop on it.  We pass processed data for tokeninzing\n'''\ndef process_en(text):\n    return [tok.text for tok in spacy_en.tokenizer(text)]\ndef process_de(text):\n    return [tok.text for tok in spacy_de.tokenizer(text)]","metadata":{"execution":{"iopub.status.busy":"2021-08-15T09:24:28.723678Z","iopub.execute_input":"2021-08-15T09:24:28.724006Z","iopub.status.idle":"2021-08-15T09:24:28.729020Z","shell.execute_reply.started":"2021-08-15T09:24:28.723976Z","shell.execute_reply":"2021-08-15T09:24:28.728120Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"Source= Field(tokenize=process_de,init_token ='<sos>',eos_token='<eos>',lower=True)\nTarget= Field(tokenize=process_en,init_token ='<sos>',eos_token='<eos>',lower=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-15T09:24:32.027199Z","iopub.execute_input":"2021-08-15T09:24:32.027549Z","iopub.status.idle":"2021-08-15T09:24:32.036111Z","shell.execute_reply.started":"2021-08-15T09:24:32.027518Z","shell.execute_reply":"2021-08-15T09:24:32.034729Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n","output_type":"stream"}]},{"cell_type":"code","source":"#Splitting multi30k dataset ,here source=german and target is English\ntrain_data,valid_data,test_data = Multi30k.splits(exts=('.de','.en'),fields =(Source,Target))","metadata":{"execution":{"iopub.status.busy":"2021-08-15T09:24:36.179941Z","iopub.execute_input":"2021-08-15T09:24:36.180414Z","iopub.status.idle":"2021-08-15T09:24:43.988622Z","shell.execute_reply.started":"2021-08-15T09:24:36.180359Z","shell.execute_reply":"2021-08-15T09:24:43.987566Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"downloading training.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"training.tar.gz: 100%|██████████| 1.21M/1.21M [00:00<00:00, 9.15MB/s]\n","output_type":"stream"},{"name":"stdout","text":"downloading validation.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"validation.tar.gz: 100%|██████████| 46.3k/46.3k [00:00<00:00, 1.44MB/s]\n","output_type":"stream"},{"name":"stdout","text":"downloading mmt_task1_test2016.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"mmt_task1_test2016.tar.gz: 100%|██████████| 66.2k/66.2k [00:00<00:00, 1.34MB/s]\n/opt/conda/lib/python3.7/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n","output_type":"stream"}]},{"cell_type":"code","source":"len(train_data),len(valid_data),len(test_data)","metadata":{"execution":{"iopub.status.busy":"2021-08-15T09:24:48.436783Z","iopub.execute_input":"2021-08-15T09:24:48.437129Z","iopub.status.idle":"2021-08-15T09:24:48.445269Z","shell.execute_reply.started":"2021-08-15T09:24:48.437096Z","shell.execute_reply":"2021-08-15T09:24:48.444129Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"(29000, 1014, 1000)"},"metadata":{}}]},{"cell_type":"code","source":"'''\nNow we will build vocabulary for tokens in each language such that each token have an index with in language and that index can be used for one hot encoding . In vocab we will add words that have atleast 2 repitation\n'''\nSource.build_vocab(train_data,min_freq=2)\nTarget.build_vocab(train_data,min_freq=2)","metadata":{"execution":{"iopub.status.busy":"2021-08-15T09:24:51.631150Z","iopub.execute_input":"2021-08-15T09:24:51.631518Z","iopub.status.idle":"2021-08-15T09:24:51.922400Z","shell.execute_reply.started":"2021-08-15T09:24:51.631486Z","shell.execute_reply":"2021-08-15T09:24:51.921475Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"'''\nNow we will create iterators, this iterators will create batches outfrom the dataset, then sort them ,pad them and sent it to the appropriate device.This done with bucket iterators, wILL RETURN batches of DATA WITH SRC AND TRG attributes. This is Converted into indexed format. It create batch in sach way that contains minimum amount of padding. collecting similar lenth of sentence together combining source and target\n'''\nBATCH_SIZE=128","metadata":{"execution":{"iopub.status.busy":"2021-08-15T09:24:54.419005Z","iopub.execute_input":"2021-08-15T09:24:54.419342Z","iopub.status.idle":"2021-08-15T09:24:54.425015Z","shell.execute_reply.started":"2021-08-15T09:24:54.419308Z","shell.execute_reply":"2021-08-15T09:24:54.424014Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2021-08-15T09:24:57.578470Z","iopub.execute_input":"2021-08-15T09:24:57.578793Z","iopub.status.idle":"2021-08-15T09:24:57.622830Z","shell.execute_reply.started":"2021-08-15T09:24:57.578763Z","shell.execute_reply":"2021-08-15T09:24:57.621891Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"device.type","metadata":{"execution":{"iopub.status.busy":"2021-08-15T09:25:00.765511Z","iopub.execute_input":"2021-08-15T09:25:00.765846Z","iopub.status.idle":"2021-08-15T09:25:00.772825Z","shell.execute_reply.started":"2021-08-15T09:25:00.765816Z","shell.execute_reply":"2021-08-15T09:25:00.771872Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"code","source":"#datapreprocessing is performed here,data is converted into batches and preprocess it and tokenized and padded\ntrain_iterator,valid_iterator,test_iterator = BucketIterator.splits((train_data,valid_data,test_data),batch_size=128,device=device)","metadata":{"execution":{"iopub.status.busy":"2021-08-15T09:26:54.422045Z","iopub.execute_input":"2021-08-15T09:26:54.422448Z","iopub.status.idle":"2021-08-15T09:26:54.428331Z","shell.execute_reply.started":"2021-08-15T09:26:54.422415Z","shell.execute_reply":"2021-08-15T09:26:54.427215Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n","output_type":"stream"}]},{"cell_type":"code","source":"#Encoder\n'''\nusing single layer GRU unit,produce better when campare with RNN,Use drop out. it will take previous hidden state and current input state passed. Encoder is a subclass of nn module in pytorch so we will take \ni. Here input dim is the dimension of the source langugae(german),emb_dim is the dimension of the o/p embedding layer. hid_dim is the dimension of gru unit.\n\n'''\nclass Encoder(nn.Module):\n    def __init__(self, input_dim, emb_dim, hid_dim,dropout):\n        super().__init__()\n        self.input_dim = input_dim\n        self.emb_dim   = emb_dim\n        self.hid_dim = hid_dim\n        self.embedding = nn.Embedding(input_dim,emb_dim)\n        #gru take embeded vector as input \n        self.rnn=nn.GRU(emb_dim,hid_dim)\n        self.dropout=nn.Dropout(dropout)\n        \n    '''\n    In forward method we will pass source with the help of embedding layer this get converted into a dense representatation. This dense represenatation(embeded representation into GRU unit).Unlike LSTM GRU doesnt return a cell state\n    Embedding step\n    Shape of the source is sentence length/batch size this embedded and pass into rnn we get hidden state and output tensor \n    '''\n    def forward(self,src):\n        embedded =self.dropout(self.embedding(src))#[sent len,batch size]\n        outputs,hidden =self.rnn(embedded)#[sent len ,batch size ,emb dim]\n        return hidden\n        #outputs-->#[sent len ,batch size,hid dim * n directions]\n        #hidden--->[n layers * n directions ,batch size ,hid dim]\n        \n    #hidden state is the thought vector or context vector ","metadata":{"execution":{"iopub.status.busy":"2021-08-15T10:09:42.757136Z","iopub.execute_input":"2021-08-15T10:09:42.757518Z","iopub.status.idle":"2021-08-15T10:09:42.763752Z","shell.execute_reply.started":"2021-08-15T10:09:42.757487Z","shell.execute_reply":"2021-08-15T10:09:42.762940Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"#Decoder\n'''\nDecorder operation is different from the normal seq to seq models. Here decorder take context vector or thought vector grom the encoder/GRU unit. Decoder take final hiddden state from the encoder as the intial hidden state(context). Using that it will produce tokens. Inorder to produce token decorder has to depend on the memory of the context vector it has seen  in the first place and this effects the decorders capability to generate tokens after end time steps.\nHere we will context vector,previous hidden state and current target token in each time step thus comparing to the orignal sequence to sequence models which generates a given output based on the previous hidden state and the current input token. We pass same context vectors on same GRU over and over again. So gru dimension looks like embedded dimension plu+ hidden dimension which comes from the current token and the context vector and the output dimension being the hidden dimension \n'''\nclass Decorder(nn.Module):\n    def __init__(self,output_dim,emb_dim,hid_dim,dropout):\n        super().__intial__()\n        self.emb_dim = emb_dim\n        self.hid_dim = hid_dim\n        self.output_dim=output_dim\n        self.embedding=nn.Embedding(output_dim,emb_dim)\n        #same context is passed hidden_dim comes from current token and context vector \n        self.rnn=nn.GRU(emb_dim + hid_dim , hid_dim)\n        #We will intialize a linear layer to predict the next token  only using the top layer o the decorder hidden state , we will also pass the current token and the context vector to the linear layer\n        self.out =nn,Linear(emb_dim + hid_dim*2,output_dim )\n        self.dropout=nn.Dropout(dropout)\n        '''\n        In forward method we will concatenate current token and the context vetor before feeding it to the GRU .Also concatenate current hidden state,input token and context vector before feeding it to the linear layer  \n        '''\n        \n        def forward(self,input,hidden,context):\n            #input-->[batch size]\n            #hidden-->[n layers *n directions,batch_size,hid dim]\n            #context-->[n layers *n directions,batch_size,hid dim]\n            '''Number of layers=No of dim=1\n            '''\n            #hidden-->[1,batch size,hid dim]\n            #context--->[1,batch size,hid dim]\n            input=input.unsqueeze(0)\n            #input-->[1,batch size]\n            \n            embedded=self.dropout(self.embedding(input))\n            #embedded-->[1,batch size ,emb dim]\n            \n            emb_con=torch.cat((embedded,context),dim=2)\n            #emb_con--> [1,batch size, emb dim +hid dim]\n            \n            #\n            output,hidden =self.rnn(emb_con,hidden)\n            #output-->[sent len,batch size,hid dim* n directions]\n            #hidden-->[n layers *n directions,batch size,hid dim]\n            #output ---> [1,batch size,hid dim]\n            #hidden....[1,batch_size,hid dim]\n            \n            #pass into linear layer\n            output=torch.cat((embedded.squeeze(0),hidden.squeeze(0)),dim=1)\n            #utput--->[batch size, emb dim + hid dim*2]\n            prediction=self.out(output)\n            return prediction,hidden\n            ","metadata":{"execution":{"iopub.status.busy":"2021-08-15T09:27:00.372917Z","iopub.execute_input":"2021-08-15T09:27:00.373251Z","iopub.status.idle":"2021-08-15T09:27:00.383128Z","shell.execute_reply.started":"2021-08-15T09:27:00.373201Z","shell.execute_reply":"2021-08-15T09:27:00.381838Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-08-15T10:01:28.980168Z","iopub.execute_input":"2021-08-15T10:01:28.980539Z","iopub.status.idle":"2021-08-15T10:01:28.999155Z","shell.execute_reply.started":"2021-08-15T10:01:28.980509Z","shell.execute_reply":"2021-08-15T10:01:28.997866Z"},"trusted":true},"execution_count":37,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-37-526656dd449d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mDEC_DROPOUT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0menc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mINPUT_DIM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mENC_EMB_DIM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mHID_DIM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mENC_DROPOUT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m#dec=Encoder(OUTPUT_DIM,DEC_EMB_DIM,HID_DIM,DEC_DROPOUT)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#model=Seq2Se2(enc,dec,device).to (device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"],"ename":"NameError","evalue":"name 'self' is not defined","output_type":"error"}]},{"cell_type":"code","source":"#creating a sequnce to sequnce class\nclass Seq2Seq(nn.Module):\n    def __init__(self,encoder,decoder,device):\n        super().__init__()\n        \n        self.encoder = encoder\n        self.decoder = decoder\n        self.device = device\n        '''\n        Here we are using teacher forcing .Teacher forcing is  a probabaility taht determines wheither the actual ground truth from the target has to be taken or the predication from the decorder is to be considered while predicting the next target token. if 0.25 percent from ground truth. 75 percent fromm decorder\n        '''\n    def forward(self,src,trg,teacher_forcing_ratio=0.5):\n        #src-->[sent len,batch size]\n        #trg--->[sent ean ,batch size]\n        \n        batch_size=trg.shape[1]\n        max_len=trg.shape[0]\n        target_voc_size=self.decorder.output_dim\n        #this tensor holds all outputs  from decorder.this is intialized to zero\n        outputs=torch.zeros(max_len,batch_size,target_voc_size).to(self.device)\n        #source is transimitted to form context vector. This become for decoder\n        context=self.encoder(src)\n        hidden=context\n        input=trg[0,:]\n        #for each sentence we pass input, hiddden ,context\n        for t in range(1,max_len):\n            output,hidden=self.decoder(input,hidden,context)\n            #storing output into zero intialized vector\n            outputs[t]=output\n            teacher_force=random.random() < teacher_forcing_ratio\n            topl =output.max(1)[1]\n            input=(trg[t] if teacher_force else topl)\n            \n        return outputs\n            \n        ","metadata":{"execution":{"iopub.status.busy":"2021-08-15T10:11:16.206168Z","iopub.execute_input":"2021-08-15T10:11:16.206528Z","iopub.status.idle":"2021-08-15T10:11:16.215792Z","shell.execute_reply.started":"2021-08-15T10:11:16.206497Z","shell.execute_reply":"2021-08-15T10:11:16.214675Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"INPUT_DIM=len(Source.vocab)\nOUTPUT_DIM=len(Target.vocab)\nENC_EMB_DIM=256\nDEC_EMB_DIM=256\nHID_DIM=512\nENC_DROPOUT=0.5\nDEC_DROPOUT=0.5\n\nenc=Encoder(INPUT_DIM,ENC_EMB_DIM,HID_DIM,ENC_DROPOUT)\ndec=Encoder(OUTPUT_DIM,DEC_EMB_DIM,HID_DIM,DEC_DROPOUT)\nmodel=Seq2Seq(enc,dec,device).to (device)","metadata":{"execution":{"iopub.status.busy":"2021-08-15T10:11:19.149535Z","iopub.execute_input":"2021-08-15T10:11:19.149852Z","iopub.status.idle":"2021-08-15T10:11:21.123147Z","shell.execute_reply.started":"2021-08-15T10:11:19.149824Z","shell.execute_reply":"2021-08-15T10:11:21.122307Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2021-08-15T10:12:01.159812Z","iopub.execute_input":"2021-08-15T10:12:01.160170Z","iopub.status.idle":"2021-08-15T10:12:01.166014Z","shell.execute_reply.started":"2021-08-15T10:12:01.160135Z","shell.execute_reply":"2021-08-15T10:12:01.165102Z"},"trusted":true},"execution_count":56,"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"Seq2Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(7854, 256)\n    (rnn): GRU(256, 512)\n    (dropout): Dropout(p=0.5, inplace=False)\n  )\n  (decoder): Encoder(\n    (embedding): Embedding(5893, 256)\n    (rnn): GRU(256, 512)\n    (dropout): Dropout(p=0.5, inplace=False)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"optimizer = optim.Adam(model.parameters())","metadata":{"execution":{"iopub.status.busy":"2021-08-15T11:08:37.241284Z","iopub.execute_input":"2021-08-15T11:08:37.241618Z","iopub.status.idle":"2021-08-15T11:08:37.245993Z","shell.execute_reply.started":"2021-08-15T11:08:37.241589Z","shell.execute_reply":"2021-08-15T11:08:37.244884Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"'''we dont calculate loss for padded sequnce as they are not part of the actual source and target sequences .We will ignore padded sequnce'''\npad_idx=Target.vocab.stoi['<pad>']\ncriterion=nn.CrossEntropyLoss(ignore_index=pad_idx)","metadata":{"execution":{"iopub.status.busy":"2021-08-15T10:15:55.815722Z","iopub.execute_input":"2021-08-15T10:15:55.816050Z","iopub.status.idle":"2021-08-15T10:15:55.820137Z","shell.execute_reply.started":"2021-08-15T10:15:55.816019Z","shell.execute_reply":"2021-08-15T10:15:55.819346Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"'''\nIn train function we will pass model,iterator,optimizer,criterion,clip(to avoid gradient explosion)\n'''\ndef train(model,iterator,optimizer,criterion,clip):\n    model.train()\n    epoch.loss=0\n    for i,batch in enumerate(iterator):\n        source=batch.src\n        target=batch.trg#[sentlen,batch size]\n        optimizer.zero_grad()\n        output=model(source,target)#[sent len,batch_size,output_dim]\n        #we will remove padded values before giving it to loass function\n        loss=criterion(output[1:].view(-1,output.shape[2]),target[1:].view(-1))\n        #trg-->[(sent len-1)* batch size]\n        #output-->[(sent len-1) * batch size,output dim]\n        loss.backward()\n        torch.nn.utils.clip_grad_norm(model.parameters(),clip)\n        optimizer.step()\n        epoch_loss+=loss.item()\n        \n    return epoch_loss/len(iterator)","metadata":{"execution":{"iopub.status.busy":"2021-08-15T10:26:50.143030Z","iopub.execute_input":"2021-08-15T10:26:50.143370Z","iopub.status.idle":"2021-08-15T10:26:50.149824Z","shell.execute_reply.started":"2021-08-15T10:26:50.143343Z","shell.execute_reply":"2021-08-15T10:26:50.148775Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"def evaluate(models,iterator,criterion):\n    model.eval()\n    epoch_loss=0\n    with torch.no_grad():\n        for i,batch in enumerate(iterator):\n            source=batch.src\n            target=batch.trg\n            output=model(source,target,0)\n            loss=criterion(output[l:].view(-1,output.shape[2]),target[1:].view(-1))\n            epoch_loss+=loss.item()\n    return epoch_loss/len(iterator)      \n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-08-15T10:54:10.996937Z","iopub.execute_input":"2021-08-15T10:54:10.997292Z","iopub.status.idle":"2021-08-15T10:54:11.003293Z","shell.execute_reply.started":"2021-08-15T10:54:10.997256Z","shell.execute_reply":"2021-08-15T10:54:11.002340Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"DIR='models'\nModel_DIR=os.path.join(DIR,'seq2seq_model.pt')\nN_EPOCHS=10\nCLIP=10\nbest_loss=float('inf')\n\nif not os.path.isdir(f'{DIR}'):\n    os.makedirs(f'{DIR}')\n    \n    \nfor epoch in range(N_EPOCHS):\n    train_loss=train(model,train_iterator,optimizer,criterion,CLIP)\n    valid_loss=evaluate(model,valid_iterator,criterion)\n    \n    if valid_loss<best_loss:\n        best_loss=valid_loss\n        torch.save(model.state_dict(),MODEL_DIR)\n    print(f'Epoch: {epoch+1:03}| Train Loss : {train_loss:3f} | Train PPL:{math.exp(train_loss) : 7.3f} | Val.Loss: {valid_loss:.3f} | Val.PPL: {math.exp(valid_loss):7.3f}')","metadata":{"execution":{"iopub.status.busy":"2021-08-15T11:12:55.211034Z","iopub.execute_input":"2021-08-15T11:12:55.211389Z","iopub.status.idle":"2021-08-15T11:12:55.243055Z","shell.execute_reply.started":"2021-08-15T11:12:55.211359Z","shell.execute_reply":"2021-08-15T11:12:55.241282Z"},"trusted":true},"execution_count":70,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-70-d286d3944a8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCLIP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-61-c86d2651f29b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, clip)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mepoch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'loss'"],"ename":"AttributeError","evalue":"'int' object has no attribute 'loss'","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
